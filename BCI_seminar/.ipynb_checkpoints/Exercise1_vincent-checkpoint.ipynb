{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 1: Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import constants\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The logistic function (1 point - programming)\n",
    "Write a function \"logistic(h,a=1)\" resembling the logistic function and a second function \"signtrafunc\" the more discrete tranfer function equivalent in form of a function of the sign of the input. Also write a function \"dlogistic(h,a=1)\" resembling the derivative of the logistic function.\n",
    "\n",
    "For defining the sign-based transfer function the inline definition of functions using the syntax trafunc=lambda x: f(x) might be handy, please write the logistic function, however, as a classical function definition. The a=1 in the function definition sets the default to a=1 so the function needs only 1 argument by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logistic(h,a=1):\n",
    "    returnVal = 1 / (1 + np.exp(-a * h))\n",
    "    return returnVal\n",
    "\n",
    "def dlogistic(h,a=1):\n",
    "    return (a * np.exp(-a * h)) / (1 + np.exp(-a * h))**2\n",
    "\n",
    "signtrafunc=lambda x: (np.sign(x) + 1)/2\n",
    "\n",
    "# x = np.arange(-6.0, 6.0, 0.1)\n",
    "# plt.plot(x, logistic(x))\n",
    "# plt.plot(x, dlogistic(x))\n",
    "# plt.plot(x, signtrafunc(x))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Building an artificial neuron  (2 points - programming)\n",
    "Define a class \"neuron\" resembling a simple perceptron. See https://docs.python.org/3/tutorial/classes.html for help on classes.\n",
    "\n",
    "It should have the attributes \"neuron.w\" for the weights, \"neuron.b\" for the bias, the methods \"neuron.trafunc(self,x)\" and \"neuron.dtrafunc(self,x)\" for the transfer function and the method \"neuron.out(self,x)\" to calculate the output for input *x*. \n",
    "\n",
    "Build a constructor method \"\\__init\\__(self,...)\", where self refers to the object itself, which assigns the weight vector *x*, the bias *b* , the transfer function \"trafunc\" and it's derivative \"dtrafunc\" to the neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuron:\n",
    "    \n",
    "    def __init__(self, weight, bias):\n",
    "        self.w = weight \n",
    "        self.b = bias\n",
    "        \n",
    "    def trafunc(self, h, logisticBool): \n",
    "        if(logisticBool):\n",
    "            return logistic(h)\n",
    "        else:\n",
    "            return signtrafunc(h)\n",
    "    \n",
    "    def dtrafunc(self, h, logisticBool):\n",
    "        if(logisticBool):\n",
    "            return dlogistic(h)\n",
    "        else:\n",
    "            return 0 # I think the derivation of the sign function is basically 0, or undefined/infinite on the 0 mark\n",
    "    \n",
    "#     return the \"h\" for the f(h) <- transfer function\n",
    "    def out(self, x):\n",
    "        total = 0\n",
    "        i = 0\n",
    "        for weight in self.w:\n",
    "            total += weight*x[i] - self.b\n",
    "            i = i + 1\n",
    "        return total        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Use an artificial neuron (3 points - thinking and programming)\n",
    "Use instances of the neuron class above to build the equivalents to logical \"or\" and \"and\"-functions and test them for 2-dimensional input vectors *x* resembling all possibilities of combinations ([0,0] [1,0], [0,1], [1,1]).\n",
    "\n",
    "First, use the sign-based transfer function to solve the task and then apply the same weights w and bias b on a neuron with the logistic transfer function.\n",
    "\n",
    "What's the difference?\n",
    "\n",
    "*Hint: if you haven't succeeded with Task 2, you can solve Task 3 analytically and write down the needed weights and results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Gate with Sign function\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "OR Gate with Sign function\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "AND Gate with Sign function\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "\n",
      "OR Gate with Sign function\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# AND Gate with Sign function\n",
    "print(\"AND Gate with Sign function\")\n",
    "neuron1 = neuron([20, 20], 15)\n",
    "print(neuron1.trafunc(neuron1.out([0, 0]), False))\n",
    "print(neuron1.trafunc(neuron1.out([0, 1]), False))\n",
    "print(neuron1.trafunc(neuron1.out([1, 0]), False))\n",
    "print(neuron1.trafunc(neuron1.out([1, 1]), False))\n",
    "\n",
    "# OR Gate with Sign function\n",
    "print(\"\\nOR Gate with Sign function\")\n",
    "neuron1 = neuron([30, 30], 10)\n",
    "print(neuron1.trafunc(neuron1.out([0, 0]), False))\n",
    "print(neuron1.trafunc(neuron1.out([0, 1]), False))\n",
    "print(neuron1.trafunc(neuron1.out([1, 0]), False))\n",
    "print(neuron1.trafunc(neuron1.out([1, 1]), False))\n",
    "\n",
    "# AND Gate with Logistic function\n",
    "print(\"\\nAND Gate with Sign function\")\n",
    "neuron1 = neuron([20, 20], 15)\n",
    "print(neuron1.trafunc(neuron1.out([0, 0]), True) > 0.5)\n",
    "print(neuron1.trafunc(neuron1.out([0, 1]), True) > 0.5)\n",
    "print(neuron1.trafunc(neuron1.out([1, 0]), True) > 0.5)\n",
    "print(neuron1.trafunc(neuron1.out([1, 1]), True) > 0.5)\n",
    "\n",
    "# OR Gate with Sign function\n",
    "print(\"\\nOR Gate with Sign function\")\n",
    "neuron1 = neuron([30, 30], 10)\n",
    "print(neuron1.trafunc(neuron1.out([0, 0]), True) > 0.5)\n",
    "print(neuron1.trafunc(neuron1.out([0, 1]), True) > 0.5)\n",
    "print(neuron1.trafunc(neuron1.out([1, 0]), True) > 0.5)\n",
    "print(neuron1.trafunc(neuron1.out([1, 1]), True) > 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: The XOR function (100 extra points - thinking and maybe programming)\n",
    "Build an XOR function with a neuron of the class you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doesn't make sense, because how can I make the sum of the weight * input to be less than the bias/threshold, while mainting the other conditions, for example the [0,1] or [1,0]\n"
     ]
    }
   ],
   "source": [
    "print(\"doesn't make sense, because how can I make the sum of the weight * input to be less than the bias/threshold, while mainting the other conditions, for example the [0,1] or [1,0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: The current density (4 points - analytic derivation)\n",
    "Analytically derive the current density $\\vec{J}=-\\sigma\\nabla\\phi$ of a dipole field at origin step-by-step from the potential equation $\\phi(\\vec{r})=\\frac{1}{4\\pi\\epsilon_0}\\frac{\\vec{p}\\cdot\\vec{r}}{\\left|\\vec{r}\\right|^3}$ in Cartesian coordinates.\n",
    "\n",
    "To this extent you will need to build the gradient $\\nabla=\\left(\n",
    "\\begin{array}{c}\n",
    "\t\\frac{\\delta}{\\delta x}\\\\\n",
    "\t\\frac{\\delta}{\\delta y}\\\\\n",
    "\t\\frac{\\delta}{\\delta z}\n",
    "\\end{array}\n",
    "\\right)$!\n",
    "\n",
    "You can take the dipolar moment $\\vec{p}$ to be a constant vector $\\vec{p}=\\left(\n",
    "\\begin{array}{c}\n",
    "\tp_x\\\\\n",
    "\tp_y\\\\\n",
    "\tp_z\n",
    "\\end{array}\n",
    "\\right)$. \n",
    "\n",
    "The vector $\\vec{r}=\\left(\n",
    "\\begin{array}{c}\n",
    "\tx\\\\\n",
    "\ty\\\\\n",
    "\tz\n",
    "\\end{array}\n",
    "\\right)$ is the coordinates in cartesian coordinates and  the norm is the euclidean norm $\\left|\\vec{r}\\right|=\\sqrt{x^2+y^2+z^2}$.\n",
    "\n",
    "$\\sigma$ is the specific conductivity of the material (a constant).\n",
    "\n",
    "*Hint: You can hand in the solution in your format of choice: Write direclty below (Markdown takes latex within $$, jsut double-click on the cell below), Pdf from Latex or Word, scan or photo of a hand-written derivation, etc....*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "$\\vec{J}=-\\sigma \\nabla \\phi=$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Electrical Field strength & potential of a dipole (5 points - programming)\n",
    "Write a python function resembling the electrical field potential $\\phi(\\vec{r},\\vec{r}_0)$ and another one for the field strength $\\vec{E}$ of a dipole in infinite charge free space at point $\\vec{r}_0$ in Cartesian coordinates. The function should take the position of the observed point $\\vec{r}$, the position of the dipole $\\vec{r}_0$ and the dipole moment $\\vec{p}$ as inputs and return the scalar potential. $\\vec{r}_0$ should be set to the origin by default. \n",
    "\n",
    "$\\phi(\\vec{r})=\\frac{1}{4\\pi\\epsilon_0}\\frac{\\vec{p}\\cdot\\left(\\vec{r}-\\vec{r}_0\\right)}{\\left|\\vec{r}-\\vec{r}_0\\right|^3}$\n",
    "\n",
    "$\\vec{E}=\\frac{1}{4 \\pi \\epsilon_0 } \\left(3 \\frac{\\left(\\vec{r}-\\vec{r}_0\\right) \\cdot \\vec{p}}{\\left|\\vec{r}-\\vec{r}_0\\right|^5} \\cdot \\left(\\vec{r}-\\vec{r}_0\\right)-\\frac{\\vec{p}}{\\left|\\vec{r}-\\vec{r}_0\\right|^3}\\right)$\n",
    "\n",
    "Make a plot of the two variables in two dimensions from -10 to 10 for both axes in the x/y-plane for a dipole at origin with dipole moment $\\vec{p}=[1,0]$.\n",
    "Plot the potential as decibel values using the matlpotlib function plt.contour/contourf and the field strength using the function plt.steamplot. Draw both plots into the same figure (plt.hold('on')). The arguments to the plot function call for $\\vec{E}$- and $\\phi$- values need to have the shape corresponding to the XX and YY variables from np.meshgrid (see below).\n",
    "\n",
    "*Hint: You can find $\\epsilon_0$ in the scipy constants. Numpy's tensordot might simplify the treatment of multiple positions at once.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.arange(-10,10,0.1)\n",
    "y=np.arange(-10,10,0.1)\n",
    "\n",
    "XX,YY=np.meshgrid(x,y)\n",
    "XX.shape\n",
    "\n",
    "#Calculate the field and potential on the whole meshgrid \n",
    "# phi=phi_dip([XX,YY],p)\n",
    "\n",
    "# E=E_dip([XX,YY],p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
